# -*- coding: utf-8 -*-
"""first_phase.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bBLK4CVwDAeuYCubb1geU4QnCebENIL-
"""

import os
import random
import torch
import torchvision
from torchvision import datasets, transforms, models
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms.functional as TF
import torch.optim.lr_scheduler as lr_sh
from torch.utils.data import Dataset

!pip install -q segmentation-models-pytorch
!pip install -q torchsummary
import segmentation_models_pytorch as smp
import segmentation_models_pytorch.utils

import time
import copy

import numpy
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import seaborn as sn
import pandas as pd
import numpy as np
from sklearn.model_selection import KFold

import PIL
from PIL import Image
import cv2

import matplotlib.pyplot as plt
import numpy as np

"""# DATASET"""

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

from google.colab import drive
drive.mount('/content/gdrive')

!unzip '/content/gdrive/MyDrive/Final Project/New database pictures.zip'

"""# Data Augmentation"""

!mkdir images

!mkdir masks

# !rm -r images
# !rm -r masks

l=['carcinoma_in_situ','light_dysplastic','moderate_dysplastic','normal_columnar','normal_intermediate','normal_superficiel','severe_dysplastic']
for j in range(len(l)):

  path = '/content/New database pictures/'+l[j]


  for img in os.listdir(path):
    i= path+'/'+ img
    im=Image.open(i)
    ip='/content/images/'+img
    mp='/content/masks/'+img
    n= len(i)
    if (i[n-5]!='d'):
      im.save(ip)
    else:
      im.save(mp)

path1='/content/images'
path2='/content/masks'


p1 = sorted(os.listdir(path1))
p2 = sorted(os.listdir(path2))

print(len(p1))
print(len(p2))

import matplotlib.image as mpimg

cj = transforms.ColorJitter(brightness=0.8, contrast=0, saturation=0, hue=0)
cj1 = transforms.ColorJitter(brightness=0.5, contrast=0, saturation=0.3, hue=0)
cj2 = transforms.ColorJitter(brightness=0.6, contrast=0, saturation=0, hue=0)

cj3 = transforms.ColorJitter(brightness=0.5, contrast=0, saturation=0, hue=0.5)
cj4 = transforms.ColorJitter(brightness=0.8, contrast=0, saturation=0.3, hue=0.3)
cj5 = transforms.ColorJitter(brightness=0.3, contrast=0.2, saturation=0, hue=0.3)
cj6 = transforms.ColorJitter(brightness=0.8, contrast=0.2, saturation=0, hue=0.3)
cj7 = transforms.ColorJitter(brightness=0.7, contrast=0.1, saturation=0, hue=0.3)
cj8 = transforms.ColorJitter(brightness=0.8, contrast=0.2, saturation=0.4, hue=0.3)

rs = transforms.RandomAdjustSharpness(1.3, p=0.5)

for img,msk in zip(p1,p2):

  img_path = path1+'/'+img # Making image file path
  n = len(img)
  imp = img[:(n-4)]

  msk_path = path2+'/'+msk # Making image file path
  n = len(msk)
  imp2 = msk[:(n-4)]

  im = Image.open(img_path).convert('RGB')
  mk = Image.open(msk_path).convert('RGB')

  #To PilImage
  # tp = transforms.ToPILImage(mode=None)
  # im = tp(im)
  # mk = tp(mk)

  im1 = cj(im)
  fp =  path1 + '/' + imp + 't1' +  '.BMP'
  im1.save(fp)

  mk1 = mk
  fp =  path2 + '/' + imp2 + 't1' +  '.bmp'
  mk1.save(fp)

  im2 = cj1(im)
  fp = path1 + '/' + imp + 't2' +  '.BMP'
  im2.save(fp)

  mk2 = mk
  fp =  path2 + '/' + imp2 + 't2' +  '.bmp'
  mk2.save(fp)

  im4 = cj2(im)
  fp = path1 + '/' + imp + 't3' +  '.BMP'
  im4.save(fp)

  mk4 = mk
  fp =  path2 + '/' + imp2 + 't3' +  '.bmp'
  mk4.save(fp)

  im5 = cj3(im)
  fp = path1 + '/' + imp + 't4' +  '.BMP'
  im5.save(fp)

  mk5 = mk
  fp =  path2 + '/' + imp2 + 't4' +  '.bmp'
  mk5.save(fp)

  im6 = cj4(im)
  fp = path1 + '/' + imp + 't5' +  '.BMP'
  im6.save(fp)

  mk6 = mk
  fp =  path2 + '/' + imp2 + 't5' +  '.bmp'
  mk6.save(fp)

  im7 = cj5(im)
  fp = path1 + '/' + imp + 't6' +  '.BMP'
  im7.save(fp)

  mk7 = mk
  fp =  path2 + '/' + imp2 + 't6' +  '.bmp'
  mk7.save(fp)

  im8 = cj6(im)
  fp = path1 + '/' + imp + 't7' +  '.BMP'
  im8.save(fp)

  mk8 = mk
  fp =  path2 + '/' + imp2 + 't7' +  '.bmp'
  mk8.save(fp)

  im9 = rs(im)
  fp = path1 + '/' + imp + 't8' +  '.BMP'
  im9.save(fp)

  mk9 = rs(mk)
  fp =  path2 + '/' + imp2 + 't8' +  '.bmp'
  mk9.save(fp)

  im10 = cj7(im)
  fp = path1 + '/' + imp + 't9' +  '.BMP'
  im10.save(fp)

  mk10 = mk
  fp =  path2 + '/' + imp2 + 't9' +  '.bmp'
  mk10.save(fp)

  im11 = cj8(im)
  fp = path1 + '/' + imp + 't10' +  '.BMP'
  im11.save(fp)

  mk11 = mk
  fp =  path2 + '/' + imp2 + 't10' +  '.bmp'
  mk11.save(fp)

path1='/content/images'
path2='/content/masks'


p1 = sorted(os.listdir(path1))
p2 = sorted(os.listdir(path2))

print(len(p1))
print(len(p2))

"""# Data Loading"""

class Dataset(Dataset):

    def __init__(self, images_dir, masks_dir, augmentation = None,preprocessing = None):

        self.ids = sorted(os.listdir(images_dir))
        self.idss = sorted(os.listdir(masks_dir))
        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]
        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.idss]
        self.augmentation = augmentation
        self.preprocessing = preprocessing

    def transform(self, image, mask):

        # # To PilImage
        # tp = transforms.ToPILImage(mode=None)
        # image = tp(image)
        # mask = tp(mask)

        # Resize
        resize = transforms.Resize((256,256))
        image = resize(image)
        mask = resize(mask)


        # Random horizontal flipping
        if random.random() > 0.5:
            image = TF.hflip(image)
            mask = TF.hflip(mask)

        # Random vertical flipping
        if random.random() > 0.5:
            image = TF.vflip(image)
            mask = TF.vflip(mask)

        image = numpy.array(image)
        mask = numpy.array(mask)

        return image, mask


    def __getitem__(self, i):


        # read data
        # image = cv2.imread(self.images_fps[i])
        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        # mask = cv2.imread(self.masks_fps[i])
        # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)

        image = Image.open(self.images_fps[i]).convert('RGB')
        mask = Image.open(self.masks_fps[i]).convert('RGB')

        # apply augmentations
        if self.augmentation:
            image,mask = self.transform(image=image, mask=mask)
            # sample = self.augmentation(image=image, mask=mask)
            # image, mask = sample['image'], sample['mask']

        if self.preprocessing:
          sample = self.preprocessing(image=image)
          image = sample['image']
          mask = TF.to_tensor(mask)
        else:
          image = TF.to_tensor(image)
          mask = TF.to_tensor(mask)



        return image, mask

    def __len__(self):
        return len(self.ids)

transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomRotation(degrees=45),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    transforms.ToTensor(),
])

dt = Dataset(path1,path2,augmentation = True)

train_set,val_set = torch.utils.data.random_split(dt,[6000,4087])
val_set,test_set = torch.utils.data.random_split(val_set,[3000,1087])

data_dict = {'train' : torch.utils.data.DataLoader(dataset = train_set, batch_size = 4, shuffle =True),
'val' : torch.utils.data.DataLoader(dataset = val_set, batch_size = 4, shuffle = True)}

print(data_dict['train'])

dataiter = iter(data_dict['train'])
images, masks = next(dataiter)

print(images.shape)
print(images[1].shape)
print(masks[0].shape)

"""#Image Visualization


"""

def imshow(img):
    npimg = img.numpy()
    plt.figure(figsize=(12, 4))
    plt.axis('off')
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    # plt.title(title)
    plt.show()

def show_batch_images(dataloader):
    images, labels = next(iter(dataloader))
    img = torchvision.utils.make_grid(images)
    msk = torchvision.utils.make_grid(labels)
    imshow(img)
    imshow(msk)

for i in range(6):
    show_batch_images(data_dict['train'])

"""# Model

#Unet with EfficientNet encoder

## Data Loading
"""

import albumentations as albu

def to_tensor(x, **kwargs):
    # return torch.from_numpy(x).to(dtype=torch.float32)
    return x.transpose(2, 0, 1).astype('float32')

def get_preprocessing(preprocessing_fn):

    _transform = [
        albu.Lambda(image=preprocessing_fn),
        albu.Lambda(image=to_tensor, mask=to_tensor),
    ]
    return albu.Compose(_transform)

ENCODER = 'efficientnet-b0'
ENCODER_WEIGHTS = 'imagenet'
# CLASSES = ['carcinoma_in_situ','light_dysplastic','moderate_dysplastic','normal_columnar','normal_intermediate','normal_superficiel','severe_dysplastic']
ACTIVATION = 'softmax'
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# create segmentation model with pretrained encoder
model = smp.Unet(
    encoder_name=ENCODER,
    encoder_weights=ENCODER_WEIGHTS,
    classes = 3,
    activation=ACTIVATION,
)

preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)

print(model.segmentation_head)

print(model)

dt = Dataset(
    '/content/images/',
    '/content/masks/',
    augmentation=True,
    preprocessing=get_preprocessing(preprocessing_fn),
)

train_set,val_set = torch.utils.data.random_split(dt,[6000,4087])
val_set,test_set = torch.utils.data.random_split(val_set,[3000,1087])

data_dict = {'train' : torch.utils.data.DataLoader(dataset = train_set, batch_size = 4, shuffle =True),
'val' : torch.utils.data.DataLoader(dataset = val_set, batch_size = 4, shuffle = True)}

"""## Dataset Visualization"""

dataiter = iter(data_dict['train'])
images, masks = next(dataiter)

print(images.shape)
print(images[1].shape)
print(masks[0].shape)

# images = torchvision.utils.make_grid(images)
# masks = torchvision.utils.make_grid(masks)

# #   # To PilImage
# tp = transforms.ToPILImage(mode=None)
# images = tp(images[1])

# npimg = images[3].numpy()
# plt.imshow(np.transpose(npimg, (1, 2, 0)))
# plt.title(title)
# plt.show()

# images.show()

def imshow(img):
    npimg = img.numpy()
    plt.figure(figsize=(12, 4))
    plt.axis('off')
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    # plt.title(title)
    plt.show()

def show_batch_images(dataloader):
    images, labels = next(iter(dataloader))
    img = torchvision.utils.make_grid(images)
    msk = torchvision.utils.make_grid(labels)
    imshow(img)
    imshow(msk)

for i in range(6):
    show_batch_images(dataiter)

len(dt)

"""## Model"""

loss = smp.utils.losses.DiceLoss()
metrics = [
    smp.utils.metrics.IoU(threshold = 0.5),
    smp.utils.metrics.Accuracy(threshold = 0.5),
]

optimizer = torch.optim.Adam([
    dict(params=model.parameters(), lr=0.0001),
])

# create epoch runners
# it is a simple loop of iterating over dataloader`s samples
train_epoch = smp.utils.train.TrainEpoch(
    model,
    loss=loss,
    metrics=metrics,
    optimizer=optimizer,
    device=DEVICE,
    # verbose=True,
)

valid_epoch = smp.utils.train.ValidEpoch(
    model,
    loss=loss,
    metrics=metrics,
    device=DEVICE,
    # verbose=True,
)

# train model for 20 epochs
vloss = []
tloss = []

vdloss = []
tdloss = []

n_epochs = 60

max_score = 0

for i in range(0,n_epochs):

    print('\nEpoch: {}'.format(i))
    train_logs = train_epoch.run(data_dict['train'])
    valid_logs = valid_epoch.run(data_dict['val'])

    # do something (save model, change lr, etc.)
    if max_score < valid_logs['iou_score']:
        max_score = valid_logs['iou_score']
        torch.save(model, '/content/gdrive/MyDrive/Final Project/checkpath.pth')
        print('Model saved!')

    if i == 25:
        optimizer.param_groups[0]['lr'] = 1e-5

    tloss.append(train_logs['iou_score'])
    vloss.append(valid_logs['iou_score'])

    tdloss.append(train_logs['dice_loss'])
    vdloss.append(valid_logs['dice_loss'])

"""##Plots"""

plt.title("IoU score vs. Epochs")

plt.xlabel("Epochs")
plt.ylabel("IoU score")

plt.plot(range(1,n_epochs+1),tloss,label="Train")
plt.plot(range(1,n_epochs+1),vloss,label="Validation")

plt.legend(["training_set IoU Score","Valodation_set IoU Score"])

plt.show()

plt.title("Loss vs. Epochs")

plt.xlabel("Epochs")
plt.ylabel("IoU score")

plt.plot(range(1,n_epochs+1),tdloss,label="Train")
plt.plot(range(1,n_epochs+1),vdloss,label="Validation")

plt.legend(["Training_set Loss","Validation_set Loss"])

plt.show()

"""## Testing"""

# load best saved checkpoint
best_model = torch.load('/content/gdrive/MyDrive/Final Project/checkpath_eff_30.pth')

# create test dataset
test_data = torch.utils.data.DataLoader(test_set)

# evaluate model on test set
test_epoch = smp.utils.train.ValidEpoch(
    model=best_model,
    loss=loss,
    metrics=metrics,
    device=DEVICE,
)

logs = test_epoch.run(test_data)

"""##Image Visualization


"""

def visualize(im,gt,pm):

  fig = plt.figure(figsize=(10, 7))

  rows = 1
  columns = 3

  fig.add_subplot(rows, columns, 1)

  plt.imshow(np.transpose(im, (1, 2, 0)))
  plt.axis('off')
  plt.title("Image")

  fig.add_subplot(rows, columns, 2)

  plt.imshow(np.transpose(gt, (1, 2, 0)))
  plt.axis('off')
  plt.title("Mask")

  fig.add_subplot(rows, columns, 3)

  plt.imshow(np.transpose(pm, (1, 2, 0)))
  plt.axis('off')
  plt.title("Predicted Mask")

def visualize(image, mask_true, mask_pred):
    fig, ax = plt.subplots(1, 3, figsize=(15, 5))
    ax[0].imshow(image)
    ax[0].set_title('Input image')
    ax[1].imshow(mask_true, cmap='gray')
    ax[1].set_title('Ground truth mask')
    ax[2].imshow(mask_pred, cmap='gray')
    ax[2].set_title('Predicted mask')
    plt.show()

# test dataset without transformations for image visualization

for i in range(16):

    image_vis = test_set[i][0]
    image, gt_mask = test_set[i]

    gt_mask = gt_mask.squeeze()

    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)
    pr_mask = best_model.predict(x_tensor)
    pr_mask = (pr_mask.squeeze().cpu().numpy().round())

    visualize(
        image_vis,
      gt_mask,
       pr_mask
    )